import requests as req
from bs4 import BeautifulSoup
import time
from urllib.parse import urljoin

"""
links = []

url = "https://books.toscrape.com/catalogue/category/books/travel_2/index.html"
response = req.get(url)
if response.ok:
   soup = BeautifulSoup(response.text, "lxml")
   tds = soup.findAll('article', attrs={'class': 'product_pod'})
   article = ("'article', attrs={'class': 'product_pod'}")
   for article in tds:
       a = article.find('a')
       link = a['href'].replace('../../..',"")
       links.append("https://books.toscrape.com/catalogue" + link)
       
   print(links)

with open("categ.txt", "w") as file:
     for link in links:
         file.write(link + '\n')

"""
with open ("categ.txt", "r") as inf:
     with open("livres.csv", "w") as outf:
          outf.write('Catégorie, Titre, Informations, Image, Description\n')
          for row in inf:
              url = row.strip()

              response = req.get(url)

              if response.ok:
   
                 soup = BeautifulSoup(response.text, "lxml")
                 image = soup.img
                 titre = soup.title.string
                 infos = soup.table
                 desc = soup.find('div',{"id": "product_description"}).find_next('p').get_text()
                 catego = soup.find("ul",{"class": "breadcrumb"}).find_next("li").find_next("li").find_next("li").get_text()
                 
                 tim = {"Catégorie": catego, "Titre": titre, "Image": str(image.attrs['src']), "Description": str(desc), "Informations": infos.text}
                 
                 outf.write(catego + titre + str(image.attrs['src']).text + desc + infos.text)


                 print(tim)
